{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1ri6_c45d_eWzv4i4yH4LYYZiREbgVKV7",
      "authorship_tag": "ABX9TyOSnL2GfslQjB28Qf1X6odM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Saeedaaman/GB/blob/main/CVProject_Method2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h8Rmkb6rPKZc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa1aa499-68a8-422a-85df-0715aa38ba32"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Dense, Input, Dropout, GlobalAveragePooling1D, Flatten, Conv2D, BatchNormalization, Activation, MaxPooling2D\n",
        "from keras.models import Model, Sequential\n",
        "import numpy as np\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from zipfile import ZipFile\n",
        "import os\n",
        "import cv2\n",
        "import PIL\n",
        "import PIL.Image\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow.keras import layers"
      ],
      "metadata": {
        "id": "qbLUSOByPcFe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "zipfile1= '/content/drive/MyDrive/facial_expression.zip'\n",
        "unzipdirectory='/content/drive/MyDrive'"
      ],
      "metadata": {
        "id": "w8LngRkxPnvD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "with zipfile.ZipFile(zipfile1, 'r') as zip_ref:\n",
        "    zip_ref.extractall(unzipdirectory)"
      ],
      "metadata": {
        "id": "1y3qZqocPsg9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "outputId": "8554ed7f-f500-4187-821d-d9eed568dcd9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-11cf687ba24a>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzipfile1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mzip_ref\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mzip_ref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munzipdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/lib/python3.10/zipfile.py\u001b[0m in \u001b[0;36mextractall\u001b[0;34m(self, path, members, pwd)\u001b[0m\n\u001b[1;32m   1643\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1644\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mzipinfo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmembers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1645\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extract_member\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzipinfo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpwd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1647\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/zipfile.py\u001b[0m in \u001b[0;36m_extract_member\u001b[0;34m(self, member, targetpath, pwd)\u001b[0m\n\u001b[1;32m   1698\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmember\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpwd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpwd\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1699\u001b[0m              \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargetpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1700\u001b[0;31m             \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopyfileobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1702\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtargetpath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/shutil.py\u001b[0m in \u001b[0;36mcopyfileobj\u001b[0;34m(fsrc, fdst, length)\u001b[0m\n\u001b[1;32m    185\u001b[0m                 \u001b[0mfdst_write\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mcopyfileobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfsrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlength\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m     \u001b[0;34m\"\"\"copy data from file-like object fsrc to file-like object fdst\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[0;31m# Localize variable access to minimize overhead.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "img_height = 48\n",
        "img_width = 48"
      ],
      "metadata": {
        "id": "GwF0WtBTPcUv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Train = '/content/drive/MyDrive/facial_expression/train'"
      ],
      "metadata": {
        "id": "bj1244hAP_Hl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Test = '/content/drive/MyDrive/CV Project/Dataset/test'\n"
      ],
      "metadata": {
        "id": "QLilfqoJQDvt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Spliting the data into Training, test and validation set**"
      ],
      "metadata": {
        "id": "H6uVolmOyY9L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = tf.keras.utils.image_dataset_from_directory\n",
        "Train\n",
        "validation_split=0.2\n",
        "subset=\"training\"\n",
        "seed=123\n",
        "image_size=(img_height, img_width)\n",
        "batch_size=batch_size"
      ],
      "metadata": {
        "id": "pRMWGTcvQUFp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_ds = tf.keras.utils.image_dataset_from_directory\n",
        "Train\n",
        "validation_split=0.2\n",
        "subset=\"validation\"\n",
        "seed=123\n",
        "image_size=(img_height, img_width)\n",
        "batch_size=batch_size\n"
      ],
      "metadata": {
        "id": "CqnkVMkRRBbI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normalization_layer = tf.keras.layers.Rescaling(1./255)"
      ],
      "metadata": {
        "id": "PXDFZX1lSDF8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "#normalized_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
        "#image_batch, labels_batch = next(iter(normalized_ds))\n",
        "#first_image = image_batch[0]\n",
        "# Notice the pixel values are now in `[0,1]`.\n",
        "#print(np.min(first_image), np.max(first_image))\n"
      ],
      "metadata": {
        "id": "pvECj35fTAnj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#normalized_ds1 = val_ds.map(lambda x, y:\n",
        "#                            (normalization_layer(x), y))\n",
        "#image_batch, labels_batch = next(iter(normalized_ds))\n",
        "#first_image = image_batch[0]\n",
        "# Notice the pixel values are now in `[0,1]`.\n",
        "#print(np.min(first_image), np.max(first_image))\n"
      ],
      "metadata": {
        "id": "f1rvKJs_Tnev"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_SIZE = 48\n",
        "\n",
        "resize_and_rescale = tf.keras.Sequential\n",
        "layers.Resizing(IMG_SIZE, IMG_SIZE)\n",
        "layers.Rescaling(1./255)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CpLjwtqvUFhf",
        "outputId": "a71c0aab-c001-4a48-a1f9-451a6a41c898"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.layers.preprocessing.image_preprocessing.Rescaling at 0x7fdb65f6f250>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_augmentation = tf.keras.Sequential\n",
        "layers.RandomFlip(\"horizontal_and_vertical\")\n",
        "layers.RandomRotation(0.2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ftgI63IpUphF",
        "outputId": "7f4e7113-3a8e-4a1e-d318-7ccbe6e50bd7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.layers.preprocessing.image_preprocessing.RandomRotation at 0x7fdbff2a30a0>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential\n",
        "# Add the preprocessing layers you created earlier.\n",
        "resize_and_rescale\n",
        "data_augmentation\n",
        "layers.Conv2D(16, 3, padding='same', activation='relu')\n",
        "layers.MaxPooling2D()\n",
        "# Rest of your model.\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XJdhXUaeVADd",
        "outputId": "f86c4fba-1b39-41b8-9000-78963384c53a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.layers.pooling.max_pooling2d.MaxPooling2D at 0x7fdbff2a2d10>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#aug_ds = train_ds.maplambda x, y: (resize_and_rescale(x, training=True), y)\n"
      ],
      "metadata": {
        "id": "oE97Ji7VVsLi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "def prepare(ds, shuffle=False, augment=False):\n",
        "  # Resize and rescale all datasets.\n",
        "   ds = ds.map(lambda x, y: (resize_and_rescale(x), y),\n",
        "               num_parallel_calls=AUTOTUNE)\n",
        "   if shuffle:\n",
        "      ds = ds.shuffle(1000)\n",
        "      # Batch all datasets.\n",
        "      ds = ds.batch(batch_size)\n",
        "      # Use data augmentation only on the training set.\n",
        "      if augment:\n",
        "         ds = ds.map(lambda x, y: (data_augmentation(x, training=True), y),\n",
        "                     num_parallel_calls=AUTOTUNE)\n",
        "         # Use buffered prefetching on all datasets.\n",
        "         return ds.prefetch(buffer_size=AUTOTUNE)\n",
        "\n"
      ],
      "metadata": {
        "id": "VFWRDNSkFhlY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#**Train a model**"
      ],
      "metadata": {
        "id": "9aXBo4pkHCCU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "num_classes = 7\n",
        "model = tf.keras.Sequential([\n",
        "    layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
        "    layers.MaxPooling2D(),\n",
        "    layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
        "    layers.MaxPooling2D(),\n",
        "    layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
        "    layers.MaxPooling2D(),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dense(num_classes)\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',  # Use 'categorical_crossentropy' instead of 'Categorical_Crossentropy'\n",
        "              metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "anAudvK3Gn6T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs=10\n",
        "history = model.fit(\n",
        "train_ds,\n",
        "validation_data=val_ds,\n",
        "epochs=epochs\n",
        ")"
      ],
      "metadata": {
        "id": "UJCEa940ID-N",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "outputId": "b6fef473-621a-4d17-bbe7-f2bda89bb5fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-92ee0b190513>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m history = model.fit(\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtrain_ds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36mselect_data_adapter\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m   1080\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0madapter_cls\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m         \u001b[0;31m# TODO(scottzhu): This should be a less implementation-specific error.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m   1083\u001b[0m             \"Failed to find data adapter that can handle input: {}, {}\".format(\n\u001b[1;32m   1084\u001b[0m                 \u001b[0m_type_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_type_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Failed to find data adapter that can handle input: <class 'function'>, <class 'NoneType'>"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.predict(Test)\n"
      ],
      "metadata": {
        "id": "3px4VMdmIqNy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "outputId": "9956733f-f724-4283-f31b-e533e7359f50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-7cf9748f59fb>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36mselect_data_adapter\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m   1080\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0madapter_cls\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m         \u001b[0;31m# TODO(scottzhu): This should be a less implementation-specific error.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m   1083\u001b[0m             \"Failed to find data adapter that can handle input: {}, {}\".format(\n\u001b[1;32m   1084\u001b[0m                 \u001b[0m_type_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_type_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Failed to find data adapter that can handle input: <class 'ellipsis'>, <class 'NoneType'>"
          ]
        }
      ]
    }
  ]
}